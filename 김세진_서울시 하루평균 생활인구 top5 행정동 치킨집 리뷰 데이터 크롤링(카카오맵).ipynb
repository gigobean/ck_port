{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71d49060",
   "metadata": {},
   "source": [
    "### 서울시 하루평균 생활인구 top5 행정동 치킨집 리뷰 데이터 크롤링(카카오맵)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b590037a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "\n",
    "\n",
    "# 서울시 생활 인구수가 가장 많은 상위 5개 행정동 리스트 추출\n",
    "data_raw = pd.read_excel('./data/서울시_행정동별_생활인구수.xlsx')\n",
    "data = data_raw\n",
    "data = data.sort_values(by = '총생활인구수', ascending = False)\n",
    "data_top5 = data.head(5)\n",
    "keywords = []\n",
    "keywords = data_top5['행정동명']\n",
    "\n",
    "# 상위 10개 각 행정동의 103개 치킨 업체(정확도 순) 리뷰 데이터 크롤링 후 csv 저장\n",
    "for keyword in keywords:\n",
    "    link = pd.read_csv('./data/'+keyword+\" 치킨집 카카오맵 데이터 크롤링.csv\")\n",
    "    page_urls = []\n",
    "    page_urls = link['링크주소']\n",
    "    columns = ['score', 'review']\n",
    "    \n",
    "    # Chrome 웹드라이버 설치 경로\n",
    "    excutable_path = './data/chromedriver.exe'\n",
    "    driver = webdriver.Chrome(executable_path=excutable_path)\n",
    "    source_url = \"https://map.kakao.com/\"\n",
    "    # 데이터프레임 생성\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    print(keyword, '치킨집(카카오맵) 리뷰 데이터 수집 시작')\n",
    "    print()\n",
    "\n",
    "    for page_url in page_urls: # url 갯수 만큼(103개) 반복\n",
    "\n",
    "        # 각 업체 url 접속\n",
    "        driver.get(page_url)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # 첫 페이지 추출\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        contents = soup.find(name=\"div\", attrs={\"class\":\"evaluation_review\"})\n",
    "\n",
    "        # 별점 추출\n",
    "        rates = contents.find_all(name=\"em\", attrs={\"class\":\"num_rate\"})\n",
    "\n",
    "        # 리뷰 추출\n",
    "        reviews = contents.find_all(name=\"p\", attrs={\"class\":\"txt_comment\"})\n",
    "        \n",
    "        # 별점, 리뷰 리스트 값 한개씩 붙혀서 row(series)로 구성 후 \n",
    "        # 데이터 프레임에 한줄씩 붙힘\n",
    "        for rate, review in zip(rates, reviews):\n",
    "            row = [rate.text[0], review.find(name=\"span\").text]\n",
    "            series = pd.Series(row, index=df.columns)\n",
    "            df = df.append(series, ignore_index=True)\n",
    "\n",
    "        # 2~5 페이지 까지 진행\n",
    "        for button_num in range(2, 6):\n",
    "            # 다음 페이지 버튼이 없는경우 try에서 빠져 나가도록\n",
    "            try:\n",
    "                more_reviews = driver.find_element_by_xpath(\"//a[@data-page='\" + str(button_num) + \"']\")\n",
    "                more_reviews.click()\n",
    "                time.sleep(2)\n",
    "\n",
    "                # 각 페이지 추출\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                contents = soup.find(name=\"div\", attrs={\"class\":\"evaluation_review\"})\n",
    "\n",
    "                # 별점 추출\n",
    "                rates = contents.find_all(name=\"em\", attrs={\"class\":\"num_rate\"})\n",
    "\n",
    "                # 리뷰 추출\n",
    "                reviews = contents.find_all(name=\"p\", attrs={\"class\":\"txt_comment\"})\n",
    "                \n",
    "                # 별점, 리뷰 리스트 값 한개씩 붙혀서 row(series)로 구성 후 \n",
    "                # 데이터 프레임에 한줄씩 붙힘\n",
    "                for rate, review in zip(rates, reviews):\n",
    "                    row = [rate.text[0], review.find(name=\"span\").text]\n",
    "                    series = pd.Series(row, index=df.columns)\n",
    "                    df = df.append(series, ignore_index=True)\n",
    "            except:\n",
    "                break    \n",
    "                \n",
    "    savepath = \"./data/\"\n",
    "    df.to_csv(savepath+keyword+\" 치킨집 카카오맵 리뷰 데이터 크롤링.csv\", index = False, mode='w', encoding = 'utf-8-sig')\n",
    "    print(keyword+' 완료'+'================')\n",
    "    print()\n",
    "    driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
